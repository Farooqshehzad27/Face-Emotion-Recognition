{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nfrom transformers import CLIPProcessor, CLIPModel\nfrom tqdm import tqdm\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-07-22T13:20:08.778059Z","iopub.execute_input":"2024-07-22T13:20:08.778334Z","iopub.status.idle":"2024-07-22T13:20:15.283258Z","shell.execute_reply.started":"2024-07-22T13:20:08.778311Z","shell.execute_reply":"2024-07-22T13:20:15.282239Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-22 13:20:12.258634: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-22 13:20:12.258696: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-22 13:20:12.260179: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"class FER2013Dataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n        self.images, self.labels = self._load_dataset()\n\n    def _load_dataset(self):\n        images = []\n        labels = []\n        for class_idx, class_name in enumerate(self.classes):\n            class_dir = os.path.join(self.root_dir, class_name)\n            for img_name in os.listdir(class_dir):\n                img_path = os.path.join(class_dir, img_name)\n                images.append(img_path)\n                labels.append(class_idx)\n        return images, labels\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-07-22T13:20:15.288484Z","iopub.execute_input":"2024-07-22T13:20:15.288761Z","iopub.status.idle":"2024-07-22T13:20:15.298835Z","shell.execute_reply.started":"2024-07-22T13:20:15.288716Z","shell.execute_reply":"2024-07-22T13:20:15.297961Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # CLIP expects 224x224\n    transforms.Grayscale(num_output_channels=3),  # Convert to 3-channel grayscale\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\ntrain_dataset = FER2013Dataset('/kaggle/input/fer2013/train',\n                               transform=transform)\ntest_dataset = FER2013Dataset('/kaggle/input/fer2013/test',\n                              transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True,)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False,)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T13:20:15.300399Z","iopub.execute_input":"2024-07-22T13:20:15.300775Z","iopub.status.idle":"2024-07-22T13:20:15.409304Z","shell.execute_reply.started":"2024-07-22T13:20:15.300725Z","shell.execute_reply":"2024-07-22T13:20:15.408571Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class FERModel(nn.Module):\n    def __init__(self, num_classes, device='cuda'):\n        super(FERModel, self).__init__()\n        self.clip_model = (CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").vision_model).to(device)\n        self.classifier = (nn.Linear(768, num_classes)).to(device) # CLIP's output dimension is 768\n        # Freeze CLIP parameters\n        for param in self.clip_model.parameters():\n            param.requires_grad = False\n\n    def forward(self, x):\n        with torch.no_grad():\n            features = self.clip_model(x).last_hidden_state[:, 0, :]  # Use CLS token\n        output = self.classifier(features)\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T13:20:15.411869Z","iopub.execute_input":"2024-07-22T13:20:15.412281Z","iopub.status.idle":"2024-07-22T13:20:15.419852Z","shell.execute_reply.started":"2024-07-22T13:20:15.412248Z","shell.execute_reply":"2024-07-22T13:20:15.418988Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def train(model, train_loader, criterion, optimizer, device, epoch):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}\")\n    for batch_idx, (images, labels) in progress_bar:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n        \n        progress_bar.set_postfix({\n            'Loss': f\"{running_loss/(batch_idx+1):.3f}\",\n            'Acc': f\"{100.*correct/total:.2f}%\"\n        })    \n    return running_loss / len(train_loader), 100. * correct / total","metadata":{"execution":{"iopub.status.busy":"2024-07-22T13:20:15.420982Z","iopub.execute_input":"2024-07-22T13:20:15.421311Z","iopub.status.idle":"2024-07-22T13:20:15.434891Z","shell.execute_reply.started":"2024-07-22T13:20:15.421281Z","shell.execute_reply":"2024-07-22T13:20:15.433947Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, test_loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for batch in tqdm(test_loader, desc=\"Evaluating\"):\n            images, labels = batch\n            images, labels = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            total_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    accuracy = 100. * correct / total\n    average_loss = total_loss / len(test_loader)\n    return average_loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-07-22T13:20:15.435960Z","iopub.execute_input":"2024-07-22T13:20:15.436684Z","iopub.status.idle":"2024-07-22T13:20:15.445992Z","shell.execute_reply.started":"2024-07-22T13:20:15.436660Z","shell.execute_reply":"2024-07-22T13:20:15.445051Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = FERModel(num_classes=7)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T13:20:15.447260Z","iopub.execute_input":"2024-07-22T13:20:15.447603Z","iopub.status.idle":"2024-07-22T13:20:16.507955Z","shell.execute_reply.started":"2024-07-22T13:20:15.447580Z","shell.execute_reply":"2024-07-22T13:20:16.507113Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"\ntrain_losses = []\ntrain_accuracies = []\ntest_losses = []\ntest_accuracies = []\nbest_accuracy = 0.0\n\nnum_epochs = 20\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device, epoch)\n    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n    \n    # Store metrics\n    train_losses.append(train_loss)\n    train_accuracies.append(train_acc)\n    test_losses.append(test_loss)\n    test_accuracies.append(test_acc)\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T13:20:16.509135Z","iopub.execute_input":"2024-07-22T13:20:16.509435Z","iopub.status.idle":"2024-07-22T14:19:34.493659Z","shell.execute_reply.started":"2024-07-22T13:20:16.509410Z","shell.execute_reply":"2024-07-22T14:19:34.492592Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Epoch 1: 100%|██████████| 898/898 [02:23<00:00,  6.24it/s, Loss=1.124, Acc=59.40%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20:\nTrain Loss: 1.1243, Train Acc: 59.40%\nTest Loss: 1.0103, Test Acc: 61.86%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 898/898 [02:22<00:00,  6.32it/s, Loss=0.955, Acc=64.83%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20:\nTrain Loss: 0.9550, Train Acc: 64.83%\nTest Loss: 0.9688, Test Acc: 62.76%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 898/898 [02:21<00:00,  6.34it/s, Loss=0.921, Acc=65.53%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20:\nTrain Loss: 0.9211, Train Acc: 65.53%\nTest Loss: 0.9463, Test Acc: 64.07%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 898/898 [02:22<00:00,  6.28it/s, Loss=0.902, Acc=66.25%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20:\nTrain Loss: 0.9018, Train Acc: 66.25%\nTest Loss: 0.9337, Test Acc: 64.35%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 898/898 [02:21<00:00,  6.36it/s, Loss=0.889, Acc=66.76%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20:\nTrain Loss: 0.8888, Train Acc: 66.76%\nTest Loss: 0.9352, Test Acc: 64.82%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 898/898 [02:21<00:00,  6.36it/s, Loss=0.880, Acc=67.28%]\nEvaluating: 100%|██████████| 225/225 [00:34<00:00,  6.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20:\nTrain Loss: 0.8796, Train Acc: 67.28%\nTest Loss: 0.9266, Test Acc: 64.85%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 898/898 [02:21<00:00,  6.35it/s, Loss=0.874, Acc=67.52%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20:\nTrain Loss: 0.8738, Train Acc: 67.52%\nTest Loss: 0.9184, Test Acc: 65.24%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 898/898 [02:22<00:00,  6.32it/s, Loss=0.867, Acc=67.63%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20:\nTrain Loss: 0.8671, Train Acc: 67.63%\nTest Loss: 0.9168, Test Acc: 64.68%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 898/898 [02:24<00:00,  6.22it/s, Loss=0.862, Acc=67.88%]\nEvaluating: 100%|██████████| 225/225 [00:36<00:00,  6.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20:\nTrain Loss: 0.8621, Train Acc: 67.88%\nTest Loss: 0.9143, Test Acc: 64.96%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 898/898 [02:23<00:00,  6.27it/s, Loss=0.857, Acc=68.24%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20:\nTrain Loss: 0.8569, Train Acc: 68.24%\nTest Loss: 0.9145, Test Acc: 65.42%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 898/898 [02:22<00:00,  6.29it/s, Loss=0.852, Acc=68.16%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20:\nTrain Loss: 0.8524, Train Acc: 68.16%\nTest Loss: 0.9126, Test Acc: 65.45%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 898/898 [02:23<00:00,  6.27it/s, Loss=0.849, Acc=68.39%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20:\nTrain Loss: 0.8490, Train Acc: 68.39%\nTest Loss: 0.9070, Test Acc: 65.66%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 898/898 [02:22<00:00,  6.32it/s, Loss=0.846, Acc=68.68%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20:\nTrain Loss: 0.8460, Train Acc: 68.68%\nTest Loss: 0.9076, Test Acc: 65.69%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 898/898 [02:22<00:00,  6.28it/s, Loss=0.843, Acc=68.73%]\nEvaluating: 100%|██████████| 225/225 [00:34<00:00,  6.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20:\nTrain Loss: 0.8428, Train Acc: 68.73%\nTest Loss: 0.9085, Test Acc: 65.14%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 898/898 [02:25<00:00,  6.18it/s, Loss=0.839, Acc=68.78%]\nEvaluating: 100%|██████████| 225/225 [00:34<00:00,  6.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20:\nTrain Loss: 0.8394, Train Acc: 68.78%\nTest Loss: 0.9114, Test Acc: 65.63%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|██████████| 898/898 [02:20<00:00,  6.37it/s, Loss=0.838, Acc=68.91%]\nEvaluating: 100%|██████████| 225/225 [00:34<00:00,  6.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20:\nTrain Loss: 0.8377, Train Acc: 68.91%\nTest Loss: 0.9071, Test Acc: 65.10%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17: 100%|██████████| 898/898 [02:22<00:00,  6.32it/s, Loss=0.834, Acc=68.95%]\nEvaluating: 100%|██████████| 225/225 [00:35<00:00,  6.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20:\nTrain Loss: 0.8344, Train Acc: 68.95%\nTest Loss: 0.9187, Test Acc: 65.10%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18: 100%|██████████| 898/898 [02:22<00:00,  6.32it/s, Loss=0.833, Acc=68.93%]\nEvaluating: 100%|██████████| 225/225 [00:36<00:00,  6.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20:\nTrain Loss: 0.8333, Train Acc: 68.93%\nTest Loss: 0.9021, Test Acc: 65.90%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19: 100%|██████████| 898/898 [02:24<00:00,  6.21it/s, Loss=0.831, Acc=68.98%]\nEvaluating: 100%|██████████| 225/225 [00:34<00:00,  6.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20:\nTrain Loss: 0.8307, Train Acc: 68.98%\nTest Loss: 0.9061, Test Acc: 65.55%\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20: 100%|██████████| 898/898 [02:20<00:00,  6.40it/s, Loss=0.829, Acc=69.37%]\nEvaluating: 100%|██████████| 225/225 [00:34<00:00,  6.50it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20:\nTrain Loss: 0.8291, Train Acc: 69.37%\nTest Loss: 0.9012, Test Acc: 65.83%\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, '/kaggle/working/model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:27:38.646811Z","iopub.execute_input":"2024-07-22T14:27:38.647441Z","iopub.status.idle":"2024-07-22T14:27:39.090410Z","shell.execute_reply.started":"2024-07-22T14:27:38.647398Z","shell.execute_reply":"2024-07-22T14:27:39.089609Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = torch.load('model.pth')\n","metadata":{},"execution_count":null,"outputs":[]}]}